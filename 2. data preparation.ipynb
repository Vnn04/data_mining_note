{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chuẩn bị dữ liệu** (Data preparation) là một bước quan trọng trong quá trình khai phá dữ liệu, chiếm khoảng **60-70%** thời gian của toàn bộ quá trình Data Mining. Nếu dữ liệu không được xử lý đúng cách, kết quả phân tích sẽ thiếu chính xác và không đáng tin cậy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tổng quan về Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn bị dữ liệu bao gồm:\n",
    "+ Làm sạch dữ liệu (data cleaning)\n",
    "+ Tích hợp dữ liệu (data integration)\n",
    "+ Biến đổi dữ liệu (data transformation)\n",
    "+ Giảm chiều dữ liệu (dimensionality reduction)\n",
    "+ Chia tách dữ liệu (Data splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Chi tiết các bước"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Làm sạch dữ liệu (data cleaning)\n",
    "Dữ liệu thực tế thường có lỗi, dữ liệu trống hoặc dữ liệu nhiễu. Các bước phổ biến trong làm sạch dữ liệu gồm:\n",
    "1. Xử lý giá trị thiếu (missing data)\n",
    "    + Loại bỏ hàng hoặc cột: Nếu số lượng giá trị thiếu lớn\n",
    "    + Điền giá trị thay thế:\n",
    "        + Trung bình (`mean`) hoặc trung vị (`median`) cho dữ liệu số\n",
    "        + Giá trị phổ biến nhất (`mode`) cho dữ liệu phân loại\n",
    "    + Dự đoán giá trị thiếu bằng KNN hoặc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'age': [25, 30, None, 35], 'salary': [50000, None, 60000, 58000]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   salary\n",
      "0  25.0  50000.0\n",
      "1  30.0  56000.0\n",
      "2  30.0  60000.0\n",
      "3  35.0  58000.0\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xử lý dữ liệu nhiễu (Outliers)\n",
    "    + Phương pháp loại bỏ: Loại bỏ các điểm nằm quá xa trung bình (ví dụ, 3 lần độ lệch chuẩn)\n",
    "    + Phương pháp làm mịn dữ liệu: Áp dụng kỹ thuật như binning hoặc smoothing để giảm ảnh hưởng của nhiễu\n",
    "\n",
    "3. Chuẩn hóa định dạng: Đảm bảo dữ liệu tuân theo cùng một định dạng (ví dụ ngày tháng `YYYY-MM-DD`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Tích hợp dữ liệu (Data Intergration)\n",
    "Khi dữ liệu đến từ nhiều nguồn khác nhau (ví dụ: nhiều cơ sở dữ liệu hoặc tệp csv), cần:\n",
    "+ Xử lý trùng lặp: loại bỏ hoặc hợp nhất dữ liệu trùng lặp\n",
    "+ Kết hợp dữ liệu (Joins): dùng các kỹ thuật inner join, outer join để hợp nhất dữ liệu từ nhiều bảng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2, 4], 'Score': [85, 90, 88]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   Name  Score\n",
      "0   1  Alice     85\n",
      "1   2    Bob     90\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Biến đổi dữ liệu (data transformation)\n",
    "\n",
    "Biến đổi dữ liệu giúp tăng hiệu quả của các thuật toán khai phá. Một số kỹ thuật phổ biến:\n",
    "1. Chuẩn hóa dữ liệu (normaliaztion)\n",
    "Đưa dữ liệu về cùng một thang đo để các biến có trọng số tương đương trong mô hình\n",
    "\n",
    "**Ví dụ: Min-Max Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.        ]\n",
      " [0.         0.66666667]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[200, 5000], [150, 7000], [300, 8000]]\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mã hóa dữ liệu phân loại (Encoding)\n",
    "Chuyển dữ liệu dạng phân loại thành số để mô hình có thể xử lý.\n",
    "+ Label Encoding: chuyển từng nhãn thành số nguyên.\n",
    "+ One-hot Encoding: biến mỗi nhãn thành một cột nhị phân"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([['Red'], ['Green'], ['Blue']])\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot = encoder.fit_transform(data)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tạo đặc trưng mới (Feature Engineering)\n",
    "+ Tạo ra các biến mới từ dữ liệu hiện có để cải thiện hiệu quả của mô hình\n",
    "+ Ví dụ chuyển đổi dữ liệu thời gian thành các tính năng như từ trong tuần, giờ trong ngày"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Giảm chiều dữ liệu (Dimensionality Reduction)\n",
    "Khi có quá nhiều biến (features), việc giảm chiều giúp: \n",
    "+ Tránh hiện tượng quá khớp (overfitting)\n",
    "+ Tăng tốc độ xử lý\n",
    "Các kỹ thuật phổ biến:\n",
    "+ PCA: chuyển dữ liệu sang không gian mới với ít chiều hơn\n",
    "+ Lọc đặc trưng (Feature Selection): loại bỏ những biến không quan trọng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5 Chia tách dữ liệu (Data Splitting)\n",
    "Để đánh giá mô hình, cần chia dữ liệu thành hai phần:\n",
    "+ Tập huấn luyện (training set): dùng để huấn luyện mô hình (~70-80% dữ liệu)\n",
    "+ Tập kiểm tra (test set): dùng để đánh giá độ chính xác của mô hình (~20-30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5]]\n",
    "y = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: [[1, 2], [4, 5], [2, 3]], Test Set: [[3, 4]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f\"Training Set: {X_train}, Test Set: {X_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Thách thức trong chuẩn bị dữ liệu\n",
    "+ Dữ liệu lớn: xử lý hàng triệu bản ghi đòi hỏi tài nguyên tính toán mạnh mẽ.\n",
    "+ Dữ liệu nhiễu và thiếu nhiều: Phải cân nhắc giữa việc loại bỏ hoặc dự đoán.\n",
    "+ chêch lệch phân phối dữ liệu: các tập huấn luyện và kiểm tra phải được phân phối đồng đều."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Kết luận\n",
    "Data Preparation là một bước cốt lõi trong quá trình khai phá dữ liệu. Dữ liệu chất lượng tốt là nền tảng của mô hình học máy hoặc phân tích dữ liệu cho ra kết quả chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
